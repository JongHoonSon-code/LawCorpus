{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0ff112ec-4007-45e6-9a9b-7189cb11ae98",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "importing Jupyter notebook from SetData.ipynb\n",
            "importing Jupyter notebook from mtDataset.ipynb\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/anaconda3/envs/torch109_py38/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  # Arrange GPU devices starting from 0\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0,1\"  # Set the GPU 1 to use\n",
        "\n",
        "from torch import Tensor\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import Transformer\n",
        "import math\n",
        "#여기까지 pytorch 기본 아래로는 따로 추가\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from konlpy.tag import Okt\n",
        "from tokenizers.implementations import SentencePieceBPETokenizer\n",
        "import import_ipynb\n",
        "import SetData\n",
        "from mtDataset import MTDataset\n",
        "#import model_class as mc\n",
        "#from SentencepieceTokenizer import sentencepiece_tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "0d4fd44c-cc0f-43cf-9b08-aabb71872609",
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_model(save_path, model_name, model, optimizer, valid_loss):\n",
        "    # 모델 state_dict 저장\n",
        "    torch.save(model.state_dict(), save_path + model_name + '_state_dict.pt')  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "2f4bfa35-be9b-46c3-9e2f-42998c99c0ab",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "20004\n",
            "20004\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#en 토크나이저\n",
        "corpus = '/etc/jupyterhub/pythonex/Paper_2023/Data/source.txt'\n",
        "\n",
        "sentencepiece_tokenizer = SentencePieceBPETokenizer(add_prefix_space = True)\n",
        "sentencepiece_tokenizer.train(\n",
        "    files = corpus,\n",
        "    vocab_size = 20004,\n",
        "    min_frequency = 2,\n",
        "    special_tokens = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
        ")\n",
        "vocab = sentencepiece_tokenizer.get_vocab()\n",
        "print(len(vocab))\n",
        "#print(sorted(vocab, key=lambda x: vocab[x]))\n",
        "\n",
        "#sentencepiece_tokenizer.save_model('vocab', 'source_bpe_new')\n",
        "\n",
        "#토크나이저를 통해 문장을 토큰으로 변환하는 함수\n",
        "def morphs(sentence):\n",
        "    return sentencepiece_tokenizer.encode(sentence).tokens\n",
        "\n",
        "#kr 토크나이저\n",
        "corpus = '/etc/jupyterhub/pythonex/Paper_2023/Data/target.txt'\n",
        "\n",
        "sentencepiece_tokenizer_target = SentencePieceBPETokenizer(add_prefix_space = True)\n",
        "sentencepiece_tokenizer_target.train(\n",
        "    files = corpus,\n",
        "    vocab_size = 20004,\n",
        "    min_frequency = 2,\n",
        "    special_tokens = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
        ")\n",
        "vocab = sentencepiece_tokenizer_target.get_vocab()\n",
        "print(len(vocab))\n",
        "\n",
        "#토크나이저를 통해 문장을 토큰으로 변환하는 함수\n",
        "def morphs_target(sentence):\n",
        "    return sentencepiece_tokenizer_target.encode(sentence).tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c85ef6c3-7d98-4539-b018-1d42a57cbe4c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['▁제3',\n",
              " '조,',\n",
              " '▁제7',\n",
              " '조부터',\n",
              " '▁제9조',\n",
              " '까지',\n",
              " '▁및',\n",
              " '▁제9',\n",
              " '조의2에',\n",
              " '▁따른',\n",
              " '▁등록신청',\n",
              " ',',\n",
              " '▁재외국민',\n",
              " '등록',\n",
              " '부',\n",
              " '▁등본',\n",
              " '▁교부',\n",
              " '신청',\n",
              " ',',\n",
              " '▁변경',\n",
              " '신고,',\n",
              " '▁이동',\n",
              " '신고',\n",
              " '▁및',\n",
              " '▁귀국',\n",
              " '신고',\n",
              " '는',\n",
              " '▁대통령령으로',\n",
              " '▁정하는',\n",
              " '▁바에',\n",
              " '▁따라',\n",
              " '▁다음',\n",
              " '▁각',\n",
              " '▁호의',\n",
              " '▁방법으로',\n",
              " '▁할',\n",
              " '▁수',\n",
              " '▁있다.']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "morphs('제3조, 제7조부터 제9조까지 및 제9조의2에 따른 등록신청, 재외국민등록부 등본 교부신청, 변경신고, 이동신고 및 귀국신고는 대통령령으로 정하는 바에 따라 다음 각 호의 방법으로 할 수 있다.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "55db9d76-770c-4db1-af99-a023d5fd07e4",
      "metadata": {},
      "outputs": [],
      "source": [
        "gpu_count = torch.cuda.device_count()\n",
        "DEVICE =  [torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"), torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")]\n",
        "# 스페셜 토큰 인덱스 지정\n",
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "\n",
        "# 데이터의 파일 정보\n",
        "train_file_path = \"/etc/jupyterhub/pythonex/Paper_2023/Data/train.txt\"\n",
        "valid_file_path = \"/etc/jupyterhub/pythonex/Paper_2023/Data/valid.txt\"\n",
        "\n",
        "# 데이터 불러오기\n",
        "data_pairs = SetData.load_file(train_file_path)\n",
        "train_dataset = MTDataset(data_pairs)\n",
        "data_pairs = SetData.load_file(valid_file_path)\n",
        "valid_dataset = MTDataset(data_pairs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f32a368c-a574-47f4-9f3b-ea7a9c3d7d9f",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "#데이터 구하고 처리\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from typing import Iterable, List\n",
        "\n",
        "SRC_LANGUAGE = 'ko'\n",
        "TGT_LANGUAGE = 'en'\n",
        "\n",
        "token_transform = {}\n",
        "vocab_transform = {}\n",
        "\n",
        "#토크나이저 생성 후 정의한 토큰화 함수를 딕셔너리에 저장합니다.\n",
        "token_transform[SRC_LANGUAGE] = morphs\n",
        "token_transform[TGT_LANGUAGE] = morphs_target \n",
        "\n",
        "val_iter = SetData.make_iter(valid_file_path)\n",
        "\n",
        "# 토큰 목록을 생성하기 위한 헬퍼(helper) 함수\n",
        "def yield_tokens(data_iter: Iterable, language: str) -> List[str]:\n",
        "    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n",
        "    \n",
        "    for data_sample in data_iter:\n",
        "        yield token_transform[language](data_sample[language_index[language]])\n",
        "\n",
        "# 토큰들이 어휘집(vocab)에 인덱스 순서대로 잘 삽입되어 있는지 확인\n",
        "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
        "\n",
        "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "    # 학습용 데이터 반복자(iterator)\n",
        "    train_iter = SetData.make_iter(train_file_path)\n",
        "    # torchtext의 Vocab(어휘집) 객체 생성\n",
        "    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train_iter, ln),\n",
        "                                                    min_freq=1,\n",
        "                                                    specials=special_symbols,\n",
        "                                                    special_first=True)\n",
        "\n",
        "# UNK_IDX를 기본 인덱스로 설정. 이 인덱스는 토큰을 찾지 못하는 경우에 반환\n",
        "# 만약 기본 인덱스를 설정하지 않으면 어휘집(Vocabulary)에서 토큰을 찾지 못하는 경우\n",
        "# RuntimeError가 발생\n",
        "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "    vocab_transform[ln].set_default_index(UNK_IDX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "bcfca9e5-3e35-4bdd-9524-51727ef3b357",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "19992\n",
            "19917\n"
          ]
        }
      ],
      "source": [
        "print(len(vocab_transform['ko']))\n",
        "print(len(vocab_transform['en']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "a6e7f61b-dc1f-40b5-b7f8-160736df3079",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('② 「건축법」 제4조제5항, 제5조제1항, 제6조, 제8조, 제12조제1항, 제13조제2항, 제14조제1항 각 호 외의 부분, 같은 항 제4호·제5호, 제16조제1항 본문·단서, 같은 조 제2항, 제17조제2항, 제19조제3항 본문·단서, 같은 조 제4항 각 호 외의 부분, 같은 조 제6항, 제20조제2항제3호, 같은 조 제3항·제5항, 제22조제2항 각 호 외의 부분 본문, 같은 조 제3항제2호, 제23조제1항제3호, 같은 조 제4항, 제24조제5항, 제25조제1항 전단, 같은 조 제4항부터 제6항까지, 같은 조 제8항, 제26조, 제27조제1항부터 제3항까지, 제28조제1항, 제29조제1항, 제34조, 제37조제1항·제2항, 제40조제4항, 제41조제1항, 제42조제1항 단서, 제43조제1항 각 호 외의 부분, 같은 조 제2항, 제44조제1항제2호, 같은 조 제2항, 제45조제1항 각 호 외의 부분 본문, 같은 조 제3항, 제46조제1항 단서, 같은 조 제2항, 제54조제1항 본문, 제57조제1항, 제58조, 제59조제1항제1호·제2호, 같은 조 제2항, 제60조제1항 본문·단서, 제61조제1항, 같은 조 제2항 각 호 외의 부분, 같은 조 제3항 각 호 외의 부분, 같은 항 제8호, 제62조, 제64조제1항 전단·후단, 같은 조 제2항 본문·단서, 제69조제1항제1호나목, 같은 항 제2호나목·다목, 제70조제2호·제3호, 제71조제1항제4호 후단, 같은 항 제6호 후단, 같은 항 제7호, 같은 조 제5항, 같은 조 제7항 후단, 제72조제1항 각 호 외의 부분 후단, 같은 조 제5항 전단, 같은 조 제7항, 같은 조 제8항 후단, 제73조제1항제2호, 같은 조 제3항, 제75조제2항 전단·후단, 제78조제4항, 제79조제2항 단서, 같은 조 제4항, 제80조제1항 각 호 외의 부분 단서, 같은 항 제2호, 제83조제1항·제3항, 제85조제1항제5호, 제88조제1항제7호 및 제102조제2항에서 대통령령 또는 국토교통부령으로 정하도록 한 사항은 도조례로 정할 수 있다.', '(2) Matters to be prescribed by Presidential Decree or Ordinance of the Ministry of Land, Infrastructure and Transport under Articles 4 (5), 5 (1), 6, 8, 12 (1), and 13 (2), the main sentence of Article 14 (1), and Article 14 (1) 4 and 5, the main sentence of and proviso to Article 16 (1), Articles 16 (2) and 17 (2), the main sentence of and proviso to Article 19 (3), the main sentence of Article 19 (4), Articles 19 (6) and 20 (2) 3, (3), and (5), the main sentence of Article 22 (2), Articles 22 (3) 2, 23 (1) 3 and (4), and 24 (5), the former part of Article 25 (1), Articles 25 (4) through (6) and (8), 26, 27 (1) through (3), 28 (1), 29 (1), 34, 37 (1) and (2), 40 (4), and 41 (1), the proviso to Article 42 (1), the main sentence of Article 43 (1), Articles 43 (2) and 44 (1) 2 and (2), the main sentence of Article 45 (1), Article 45 (3), the proviso to Article 46 (1), Article 46 (2), the main sentence of Article 54 (1), Articles 57 (1), 58, and 59 (1) 1 and 2, and (2), the main sentence of and proviso to Article 60 (1), Articles 61 (1), the main sentence of Article 61 (2), the main sentence of Article 61 (3), Articles 61 (3) 8 and 62, the former and latter parts of Article 64 (1), the main sentence of and proviso to Article 64 (2), Article 69 (1) 1 (b) and 2 (b) and (c), subparagraphs 2 and 3 of Article 70, the latter part of Article 71 (1) 4, the latter part of Article 71 (1) 6, Article 71 (1) 7 and (5), the latter part of Article 71 (7), the latter part of the main sentence of Article 72 (1), the former part of Article 72 (5), Article 72 (7), the latter part of Article 72 (8), Article 73 (1) 2 and (3), the former and latter parts of Article 75 (2), Article 78 (4), the proviso to Article 79 (2), Article 79 (4), the proviso to Article 80 (1), and Articles 80 (1) 2, 83 (1) and (3), 85 (1) 5, 88 (1) 7, and 102 (2) of the Building Act, may be prescribed by Provincial Ordinance.')\n",
            "<class 'tuple'>\n",
            "('② 「산지관리법」 제8조제1항·제2항, 제9조제1항부터 제3항까지, 제10조제3호부터 제5호까지, 같은 조 제10호, 제11조제1항제4호, 제12조제1항제2호부터 제6호까지, 같은 항 제8호, 같은 항 제10호부터 제16호까지, 같은 조 제2항제3호, 같은 항 제4호 각 목 외의 부분, 같은 호 가목 단서, 같은 항 제5호부터 제8호까지, 같은 조 제3항제2호, 제13조제4항, 제13조의2제3항, 제14조제1항·제2항, 제15조제1항 각 호 외의 부분 후단, 같은 조 제2항·제3항, 제17조제1항제1호 본문, 같은 항 제2호 본문, 같은 조 제2항, 제18조제2항제1호·제2호, 같은 조 제4항, 같은 조 제5항 본문·단서, 제20조제1항 각 호 외의 부분 본문, 제21조제1항 각 호 외의 부분 본문, 같은 조 제2항·제3항, 제22조제4항, 제25조제1항 각 호 외의 부분 본문·단서, 같은 조 제2항, 같은 조 제3항제1호·제2호, 같은 조 제4항, 제25조의2 각 호 외의 부분 단서, 제25조의3제1항제1호·제2호·제4호, 제25조의4제2호부터 제4호까지, 제26조, 제28조제1항제2호·제4호, 같은 항 제5호 본문, 같은 조 제2항 각 호 외의 부분, 같은 항 제2호·제3호, 같은 조 제3항 전단, 제29조제1항 전단, 같은 조 제3항·제5항, 제30조제1항·제3항, 같은 조 제5항 본문, 제37조제1항 각 호 외의 부분, 같은 조 제4항, 제38조제1항·제2항, 제39조제2항 각 호 외의 부분 본문, 같은 조 제3항·제5항, 제40조제1항 전단, 같은 조 제3항·제4항, 제42조제2항·제3항, 제43조제3항, 제47조제5항, 제49조 각 호 외의 부분, 제50조 각 호 외의 부분 본문·단서(도지사의 권한에 관한 수수료에 한정한다) 및 제57조제3항(이양된 권한에 따른 과태료의 부과·징수에 한정한다)에서 대통령령 또는 농림축산식품부령으로 정하도록 한 사항은 도조례로 정할 수 있다.', \"(2) Matters to be prescribed by Presidential Decree or Ordinance of the Ministry of Agriculture, Food and Rural Affairs under Article 8 (1) and (2), Article 9 (1) through (3), subparagraphs 3 through 5 and 10 of Article 10, Articles 11 (1) 4, 12 (1) 2 through 6, 8, and 10 through 16, and 12 (2) 3, and the main sentence of Article 12 (2) 4, the proviso to Article 12 (2) 4 (a), Articles 12 (2) 5 through 8, 12 (3) 2, 13 (4), 13-2 (3), and 14 (1) and (2), the latter part of the main sentence of Article 15 (1), Article 15 (2) and (3), the main sentences of Article 17 (1) 1 and 2, Articles 17 (2) and 18 (2) 1 and 2 and (4), the main sentence of and proviso to Article 18 (5), the main sentence of Article 20 (1), the main sentence of Article 21 (1), Articles 21 (2) and (3), 22 (4), the main sentence of and proviso to Article 25 (1), Article 25 (2) and (3) 1 and 2, and (4), the proviso to Article 25-2, Article 25-3 (1) 1, 2, and 4, subparagraphs 2 through 4 of Article 25-4, Articles 26 and 28 (1) 2 and 4, the main sentence of Article 28 (1) 5, the main sentence of Article 28 (2), Article 28 (2) 2 and 3, the former part of Article 28 (3), the former part of Article 29 (1), Articles 29 (3) and (5) and 30 (1) and (3), the main sentence of Article 30 (5), the main sentence of Article 37 (1), Articles 37 (4) and 38 (1) and (2), the main sentence of Article 39 (2), Article 39 (3) and (5), the former part of Article 40 (1), Articles 40 (3) and (4), 42 (2) and (3), 43 (3), and 47 (5), the main sentence of Article 49, the main sentence of and proviso to Article 50 (limited to fees collected under the Governor's authority), and Article 57 (3) (limited to the imposition and collection of administrative fines under devolved authority) of the Mountainous Districts Management Act, may be prescribed by Provincial Ordinance.\")\n",
            "<class 'tuple'>\n",
            "('다만, 제3조제3항, 제6조, 제7조의2, 제11조제1항, 제20조제7호, 제21조제6호, 제29조제1항ㆍ제3항ㆍ제4항중 「실용신안법」 관련 개정부분, 제31조, 제36조제3항, 제49조, 제52조, 제53조, 제55조제1항ㆍ제3항ㆍ제4항중 「실용신안법」 관련 개정부분, 제56조제1항, 제58조, 제58조의2, 제59조제3항, 제62조, 제63조의2, 제64조, 제87조제2항, 제88조제4항, 제102조제4항중 「실용신안법」 관련 개정부분, 제104조제1항, 제133조제1항, 제133조의2제4항, 제135조제1항, 제154조제8항, 제193조제1항, 제202조제3항중 「실용신안법」 관련 개정부분, 동조제4항, 제204조 및 제205조중 기준일 관련 개정부분, 제208조제3항, 제209조, 제213조, 제215조중 「실용신안법」 관련 개정부분, 제229조의2의 개정규정은 2006년 10월 1일부터 시행하고, 제3조제2항, 제4조, 제15조제1항, 제35조, 제55조제3항중 특허이의신청 관련 개정부분, 제57조제1항, 제65조제6항, 제69조 내지 제78조, 제78조의2, 제84조제1항, 제132조의3, 제136조제1항ㆍ제6항, 제137조제1항, 제140조의2, 제148조, 제164조제1항, 제165조제3항ㆍ제4항중 특허이의신청 관련 개정부분, 제171조제2항, 제172조, 제176조제1항ㆍ제2항, 제181조제1항, 제212조, 제214조제5항, 제215조, 제217조제1항중 특허이의신청 관련 개정부분, 동조제2항, 제217조의2제1항ㆍ제2항중 특허이의신청 관련 개정부분, 제224조의2제1항중 특허이의신청 관련 개정부분, 제226조제2항, 제228조의 개정규정은 2007년 7월 1일부터 시행한다.', 'Provided, That the amended provisions of Articles 3 (3), 6, 7-2 and 11 (1), subparagraph 7 of Article 20, subparagraph 6 of Article 21, and Articles 29 (1), (3) and (4) (amendments related to the Utility Model Act), 31, 36 (3), 49, 52, 53, 55 (1), (3) and (4) (amendments related to the Utility Model Act), 56 (1), 58, 58-2, 59 (3), 62, 63-2, 64, 87 (2), 88 (4), 102 (4) (amendments related to the Utility Model Act), 104 (1), 133 (1), 133-2 (4), 135 (1), 154 (8), 193 (1), 202 (3) (amendments related to the Utility Model Act) and (4), 204 and 205 (amendments related to the relevant date), 208 (3), 209, 213, 215 (amendments related to the Utility Model Act), and 229-2 shall take effect on October 1, 2006; and the amended provisions of Articles 3 (2), 4, 15 (1), 35, 55 (3) (amendments related to the patent objections), 57 (1), 65 (6), 69 through 78, 78-2, 84 (1), 132-3, 136 (1) and (6), 137 (1), 140-2, 148, 164 (1), 165 (3) and (4) (amendments related to the patent objections), 171 (2), 172, 176 (1) and (2), 181 (1), 212, 214 (5), 215, 217 (1) (amendments related to the patent objections) and (2), 217-2 (1) and (2) (amendments related to the patent objections), 224-2 (1) (amendments related to the patent objections), 226 (2), and 228, on July 1, 2007.')\n",
            "<class 'tuple'>\n",
            "('①선거소청에 관하여는 이 법에 규정된 것을 제외하고는 「행정심판법」 제10조(위원의 제척ㆍ기피ㆍ회피)(이 경우 \"위원장\"은 \"중앙선거관리위원회 또는 시ㆍ도선거관리위원회\"로 본다), 제15조(선정대표자), 제16조(청구인의 지위 승계)제2항부터 제4항까지(이 경우 \"법인\"은 \"정당\"으로 본다), 제17조(피청구인의 적격 및 경정)제2항부터 제6항까지, 제18조(대리인의 선임), 제19조(대표자 등의 자격), 제20조(심판참가), 제21조(심판참가의 요구), 제22조(참가인의 지위), 제29조(청구의 변경), 제30조(집행정지)제1항, 제32조(보정), 제33조(주장의 보충), 제34조(증거서류 등의 제출), 제35조(자료의 제출 요구 등)제1항부터 제3항까지, 제36조(증거조사), 제37조(절차의 병합 또는 분리), 제38조(심리기일의 지정과 변경), 제39조(직권심리), 제40조(심리의 방식), 제41조(발언 내용 등의 비공개), 제42조(심판청구 등의 취하), 제43조(재결의 구분)제1항ㆍ제2항, 제51조(행정심판 재청구의 금지), 제55조(증거서류 등의 반환), 제56조(주소 등 송달장소 변경의 신고의무), 제57조(서류의 송달) 및 제61조(권한의 위임)의 규정을 준용하고, 선거소청비용에 관하여는 「민사소송법」을 준용하되, 「행정심판법」을 준용하는 경우 \"행정심판\"은 \"선거소청\"으로, \"청구인\"은 \"소청인\"으로, \"피청구인\"은 \"피소청인\"으로, \"심판청구 또는 심판\"은 \"소청\"으로, \"심판청구서\"는 \"소청장\"으로, \"재결\"은 \"결정\"으로, \"재결기간\"은 \"결정기간\"으로, \"위원회\"는 \"중앙선거관리위원회 또는 시ㆍ도선거관리위원회\"로, \"재결서\"는 \"결정서\"로 본다.', '(1) Except matters as prescribed by this Act in relation to election petitions, Articles 10 (in such cases, \"chairperson\" shall be deemed a \"National Election Commission or City/Do Election Commission\"), 15, 16 (2) through (4) (in such cases, \"corporation\" shall be deemed \"political party\"), 17 (2) through (6), 18, 19, 20, 21, 22, 29, 30 (1), 32, 33, 34, 35 (1) through (3), 36, 37, 38, 39, 40, 41, 42, 43 (1) and (2), 51, 55, 56, 57, and 61 of the Administrative Appeals Act shall apply mutatis mutandis to the election petition, and the Civil Procedure Act shall apply mutatis mutandis to the expenses for the election petition, but where the Administrative Appeals Act apply mutatis mutandis, the term \"administrative appeals\" means \"election petition\"; the term \"requester\" means \"petitioner\"; the term \"requestee\" means \"petitionee\"; the term \"request for administrative appeals or administrative appeals\" means \"petition\"; the term \"written request for administrative appeals\" means \"written petition\"; the term \"ruling\" means \"decision\"; the term \"ruling period\" means \"decision period\"; the term \"committee\" means \"National Election Commission or City/Do election commission\"; the term \"written ruling\" means \"written decision\".')\n",
            "<class 'tuple'>\n",
            "('다만, 제26조의2제1항, 제78조의3제5항[법 제70조의2제1항에 따른 성실신고확인대상사업자(직전 과세기간의 총수입금액을 기준으로 한다)에 한정한다] 및 제157조제4항(「자본시장과 금융투자업에 관한 법률」에 따른 주권상장법인이 아닌 법인의 주식등에 해당하는 경우는 제외한다)ㆍ제5항의 개정규정은 2016년 4월 1일부터 시행하고, 제40조의4의 개정규정은 2016년 6월 1일부터 시행하며, 제207조의10 및 별표 3의3의 개정규정(현금영수증 의무발행업종으로서 법 제162조의3제4항에 해당하는 경우로 한정한다)은 2016년 7월 1일부터 시행하고, 제55조제1항제7호의2[복식부기의무자 중 성실신고확인대상사업자(매각일이 속하는 과세기간의 직전 과세기간의 총수입금액을 기준으로 한다)가 아닌 사업자에 한정한다], 제78조의3제1항ㆍ2항 및 같은 조 제4항부터 제11항까지[복식부기의무자 중 성실신고확인대상사업자(직전 과세기간의 총수입금액을 기준으로 한다)가 아닌 사업자에 한정한다], 제78조의3제3항[복식부기의무자 중 성실신고확인대상사업자(취득일이 속하는 과세기간의 전 과세기간의 총수입금액을 기준으로 한다)가 아닌 사업자에 한정한다] 및 제157조제4항(「자본시장과 금융투자업에 관한 법률」에 따른 주권상장법인이 아닌 법인의 주식등에 해당하는 경우에 한정한다), 제211조 제7항부터 제12항까지 및 제211조의2의 개정규정은 2017년 1월 1일부터 시행하며, 제19조, 제41조제14항ㆍ제15항, 제42조의2제4항제4호, 제87조제3호, 제186조제1항ㆍ제2항, 제202조제4항 및 제202조의4의 개정규정은 2018년 1월 1일부터 시행한다.', 'Provided, That the amended provisions of Articles 26-2 (1), 78-3 (5) (limited to business operators subject to confirmation of compliant filing under Article 70-2 (1) of the Act (based on gross revenue for the immediately preceding taxable period)), 157 (4) (excluding where stocks, etc. of any corporation other than listed corporations under the Financial Investment Services and Capital Markets Act are involved), and 157 (5) shall enter into force on April 1, 2016; the amended provisions of Article 40-4 on June 1, 2016; the amended provisions of Article 207-10 and attached Table 3-3 (limited to the types of business subject to issuance of cash receipts under Article 162-3 (4) of the Act) on July 1, 2016; the amended provisions of Article 55 (1) 7-2 (limited to business operators who are not subject to confirmation of compliant filing (based on gross revenue for the taxable period immediately preceding the taxable period in which a sale takes place), among persons subject to double-entry bookkeeping), Article 78-3 (1), (2), and (4) through (11) (limited to business operators who are not subject to confirmation of compliant filing (based on gross revenue for the immediately preceding taxable period), among persons subject to double-entry bookkeeping), Article 78-3 (3) (limited to business operators who are not subject to confirmation of compliant filing (based on gross revenue for the taxable period immediately preceding the taxable period in which acquisition takes place), among persons subject to double-entry bookkeeping), Article 157 (4) (limited to where stocks, etc. of any corporation other than listed corporations under the Financial Investment Services and Capital Markets Act are involved), Article 211 (7) through (12), and Article 211-2 on January 1, 2017; and the amended provisions of Articles 19, 41 (14) and (15), and 42-2 (4) 4, subparagraph 3 of Article 87, and Articles 186 (1) and (2), 202 (4), and 202-4 shall enter into force on January 1, 2018.')\n",
            "<class 'tuple'>\n",
            "('④ 「도시개발법」 제3조제5항, 제4조제1항 단서, 같은 조 제4항 후단, 제5조제1항제17호, 같은 조 제3항·제4항, 제6조제1항, 제7조제1항 후단, 같은 조 제2항, 제8조제1항 단서, 제9조제5항 전단, 같은 조 제6항제2호, 제10조제2항제1호 단서, 같은 항 제2호 단서, 같은 조 제4항 전단, 제11조제2항 각 호 외의 부분 전단, 같은 조 제3항·제4항, 같은 조 제5항 본문, 같은 조 제8항제4호, 제12조제1항, 같은 조 제2항 본문, 같은 조 제3항·제4항, 제13조제1항, 같은 조 제2항 단서, 제15조제3항, 제16조제4항, 제17조제1항 전단, 같은 조 제4항 단서, 같은 조 제5항, 제19조제3항 후단, 제20조제2항 각 호 외의 부분, 같은 조 제5항·제8항, 제21조제2항제1호부터 제3호까지, 같은 조 제3항, 제22조제4항, 제23조제1항 본문, 같은 조 제2항·제3항, 제25조제1항, 제26조제2항, 제27조, 제28조제1항제6호, 같은 조 제3항·제5항, 제29조제2항 단서, 같은 조 제3항 본문·단서, 제31조제2항, 제40조제1항·제4항·제5항, 제44조제3항, 제45조, 제46조제2항, 제50조제1항, 제53조 단서, 제55조제4항·제5항, 제58조제1항·제3항, 같은 조 제4항 전단, 제59조 본문, 제60조제2항제9호, 제61조제1항제3호·제8호, 같은 조 제3항, 제62조제4항, 제63조제1항제3호, 같은 조 제3항 및 제72조제4항·제5항에서 대통령령 또는 국토교통부령으로 정하도록 한 사항은 도조례로 정할 수 있다.', '(4) Matters to be prescribed by Presidential Decree or Ordinance of the Ministry of Land, Infrastructure and Transport under Article 3 (5), the proviso to Article 4 (1), the latter part of Article 4 (4), Articles 5 (1) 17, (3), and (4), and 6 (1), the latter part of Article 7 (1), Article 7 (2), the proviso to Article 8 (1), the former part of Article 9 (5), Article 9 (6) 2, the proviso to Article 10 (2) 1, the proviso to Article 10 (2) 2, the former part of Article 10 (4), the former part of Article 11 (2), Article 11 (3) and (4), the main sentence of Article 11 (5), Articles 11 (8) 4 and 12 (1), the main sentence of Article 12 (2), Articles 12 (3) and (4) and 13 (1), the proviso to Article 13 (2), Articles 15 (3) and 16 (4), the former part of Article 17 (1), the proviso to Article 17 (4), Article 17 (5), the latter part of Article 19 (3), the main sentence of Article 20 (2), Articles 20 (5) and (8), 21 (2) 1 through 3, and (3), and 22 (4), the main sentence of Article 23 (1), Articles 23 (2) and (3), 25 (1), 26 (2), 27, and 28 (1) 6, (3), and (5), the proviso to Article 29 (2), the main sentence of and proviso to Article 29 (3), Articles 31 (2), 40 (1), (4), and (5), 44 (3), 45, 46 (2), and 50 (1), the proviso to Article 53, Articles 55 (4) and (5) and 58 (1) and (3), the former part of Article 58 (4), the main sentence of Article 59, Articles 60 (2) 9, 61 (1) 3 and 8, and (3), 62 (4), 63 (1) 3 and (3), and 72 (4) and (5) of the Urban Development Act, may be prescribed by Provincial Ordinance.')\n",
            "<class 'tuple'>\n",
            "('③ 부칙 제4조제3항의 개정규정에도 불구하고 이 법 시행 당시 종전의 「원자력안전법」제2조제17호, 제10조제1항 단서, 같은 조 제2항, 같은 조 제4항 및 같은 조 제5항, 제11조제1호, 제12조제1항 단서 및 같은 조 제2항, 제15조제1항 단서, 제18조, 제20조제1항 단서 및 같은 조 제2항, 제25조, 제28조제1항 단서, 제30조제1항 단서 및 같은 조 제2항 본문, 제31조제2항, 제35조제1항 단서, 같은 조 제2항 단서 및 같은 조 제3항, 제36조제1호, 제39조, 제42조제1항 단서, 제45조제1항 각 호 외의 부분 단서 및 같은 조 제2항, 제46조제1호, 제49조, 제52조제1항제2호 및 같은 조 제4항, 제53조제1항 단서, 같은 조 제2항 전단 및 같은 조 제3항 본문, 제54조제1항제6호 및 같은 조 제3항, 제55조제2항제1호 및 같은 조 같은 항 제3호, 제58조, 제60조제1항 단서 및 같은 조 제2항, 제63조제1항 단서 및 같은 조 제2항, 제64조제1호, 제67조, 제70조제2항 및 같은 조 제4항, 제71조제1항 및 같은 조 제2항 전단, 제74조제1항, 제76조제1항 전단ㆍ단서 및 같은 조 제2항, 제78조제3항, 제79조제1호 및 같은 조 제2호, 제82조, 제86조제2항, 제88조제1항, 제94조제2호 및 같은 조 제3호, 제100조제1항, 제103조제2항, 제104조제1항 각 호 외의 부분, 제105조제3항, 제106조제3항 및 제112조 본문에 따른 원자력안전위원회규칙은 이 법 시행일 이후 3개월의 범위 내에서 총리령이 발할 때까지 총리령으로 본다.', '(3) Notwithstanding the amended provisions of Article 4 (3) of the Addenda, \"Rules of the Nuclear Safety and Security Commission\" under subparagraph 17 of Article 2, proviso to Article 10 (1), Article 10 (2), (4) and (5), subparagraph 1 of Article 11, proviso to Article 12 (1), Article 12 (2), proviso to Article 15 (1), Article 18, proviso to Article 20 (1), Articles 20 (2) and 25, provisos to Articles 28 (1) and to 30 (1), main sentence of Article 30 (2), Article 31 (2), provisos to Article 35 (1) and to 35 (2), Article 35 (3), subparagraph 1 of Article 36, Article 39, proviso to Article 42 (1), proviso to part other than each subparagraph of Article 45 (1), Article 45 (2), subparagraph 1 of Article 46, Articles 49, 52 (1) 2 and (4), proviso to Article 53 (1), former part of Article 53 (2), main sentence of Article 53 (3), Articles 54 (1) 6 and (3), 55 (2) 1, 55 (2) 3, Article 58, proviso to Article 60 (1), Article 60 (2), proviso to Article 63 (1), Article 63 (2), subparagraph 1 of Article 64, Articles 67, 70 (2) and (4), 71 (1), former part of Article 71 (2), Article 74 (1), former part of and proviso to Article 76 (1), Articles 76 (2) and 78 (3), subparagraphs 1 and 2 of Article 79, Articles 82, 86 (2), 88 (1), subparagraphs 2 and 3 of Article 94, Articles 100 (1), 103 (2), part other than each subparagraph of Article 104 (1), Articles 105 (3), 106 (3), and main sentence of Article 112 of the Nuclear Safety Act at the time this Act enters into force shall be deemed Ordinance of the Prime Minister until Ordinance of the Prime Minister is issued within the range of three months from the date on which this Act enters into force.')\n",
            "<class 'tuple'>\n",
            "1229215\n",
            "136000\n"
          ]
        }
      ],
      "source": [
        "cnt = 0\n",
        "for data_sample in train_dataset:\n",
        "  print(data_sample)\n",
        "  print(type(data_sample))\n",
        "  cnt += 1\n",
        "  if (cnt > 5):\n",
        "    break\n",
        "    \n",
        "for data_sample in valid_dataset:\n",
        "  print(data_sample)\n",
        "  print(type(data_sample))\n",
        "  cnt += 1\n",
        "  if (cnt > 5):\n",
        "    break\n",
        "    \n",
        "print(len(train_dataset))\n",
        "print(len(valid_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "970a82ab-daa2-4b90-9117-04b462ca4315",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "#학습하는 동안, 모델이 예측하는 동안 정답(이후 출현하는 단어)을 보지 못하도록 하는 후속 단어 마스크(subsequent word mask)\n",
        "def generate_square_subsequent_mask(sz):\n",
        "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE[0])) == 1).transpose(0, 1) #상삼각행렬을 이용해 1로 채워진 텐서의 하위 값을 0으로 변경하고, 행/열 위치를 변경\n",
        "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "    return mask\n",
        "\n",
        "#출발어와 도착어의 패딩(padding) 토큰들 또한 숨겨야 합니다. 아래에 두 가지 모두를 처리\n",
        "def create_mask(src, tgt):\n",
        "    src_seq_len = src.shape[0]\n",
        "    tgt_seq_len = tgt.shape[0]\n",
        "\n",
        "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
        "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE[0]).type(torch.bool)\n",
        "\n",
        "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
        "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
        "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "076e4128-3404-42d8-a6c0-6bbe60050c82",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 단어 순서 개념(notion)을 토큰 임베딩에 도입하기 위한 위치 인코딩(positional encoding)을 위한 헬퍼 모듈(Module)\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self,\n",
        "                 emb_size: int,\n",
        "                 dropout: float,\n",
        "                 maxlen: int = 5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
        "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
        "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
        "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
        "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
        "        pos_embedding = pos_embedding.unsqueeze(-2) # 뒤에서 2번째 자리에 1로 채워진 차원 추가\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        #self.register_buffer('pos_embedding', pos_embedding)\n",
        "\n",
        "    def forward(self, token_embedding: Tensor):\n",
        "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
        "\n",
        "# 입력 인덱스의 텐서를 해당하는 토큰 임베딩의 텐서로 변환하기 위한 헬퍼 모듈(Module)\n",
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size: int, emb_size):\n",
        "        super(TokenEmbedding, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
        "        self.emb_size = emb_size\n",
        "\n",
        "    def forward(self, tokens: Tensor):\n",
        "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
        "\n",
        "# Seq2Seq 신경망\n",
        "class Seq2SeqTransformer(nn.Module):\n",
        "    def __init__(self,\n",
        "                 num_encoder_layers: int,\n",
        "                 num_decoder_layers: int,\n",
        "                 emb_size: int,\n",
        "                 nhead: int,\n",
        "                 src_vocab_size: int,\n",
        "                 tgt_vocab_size: int,\n",
        "                 dim_feedforward: int = 512,\n",
        "                 dropout: float = 0.1):\n",
        "        super(Seq2SeqTransformer, self).__init__()\n",
        "        self.transformer = Transformer(d_model=emb_size,\n",
        "                                       nhead=nhead,\n",
        "                                       num_encoder_layers=num_encoder_layers,\n",
        "                                       num_decoder_layers=num_decoder_layers,\n",
        "                                       dim_feedforward=dim_feedforward,\n",
        "                                       dropout=dropout)\n",
        "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
        "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
        "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
        "        self.positional_encoding = PositionalEncoding(\n",
        "            emb_size, dropout=dropout)\n",
        "\n",
        "    def forward(self,\n",
        "                src: Tensor,\n",
        "                trg: Tensor,\n",
        "                src_mask: Tensor,\n",
        "                tgt_mask: Tensor,\n",
        "                src_padding_mask: Tensor,\n",
        "                tgt_padding_mask: Tensor,\n",
        "                memory_key_padding_mask: Tensor):\n",
        "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
        "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
        "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n",
        "                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
        "        return self.generator(outs)\n",
        "\n",
        "    def encode(self, src: Tensor, src_mask: Tensor):\n",
        "        return self.transformer.encoder(self.positional_encoding(\n",
        "                            self.src_tok_emb(src)), src_mask)\n",
        "\n",
        "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
        "        return self.transformer.decoder(self.positional_encoding(\n",
        "                          self.tgt_tok_emb(tgt)), memory,\n",
        "                          tgt_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "46b3f4d6-45e5-4c56-8dbb-655402104cbb",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "#데이터 반복자(iterator)는 원시 문자열의 쌍을 생성\n",
        "#이 문자열 쌍들을 이전에 정의한 Seq2Seq 신경망에서 처리할 수 있도록 텐서 묶음(batched tensor)으로 변환\n",
        "#이제 원시 문자열들의 묶음(batch)을 텐서 묶음으로 변환하여 모델에 직접 전달할 수 있도록 하는 대응어(collate) 함수를 정의\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# 순차적인 작업들을 하나로 묶는 헬퍼 함수\n",
        "def sequential_transforms(*transforms):\n",
        "    def func(txt_input):\n",
        "        for transform in transforms:\n",
        "            txt_input = transform(txt_input)\n",
        "        return txt_input\n",
        "    return func\n",
        "\n",
        "# BOS/EOS를 추가하고 입력 순서(sequence) 인덱스에 대한 텐서를 생성하는 함수\n",
        "def tensor_transform(token_ids: List[int]):\n",
        "    return torch.cat((torch.tensor([BOS_IDX]),\n",
        "                      torch.tensor(token_ids),\n",
        "                      torch.tensor([EOS_IDX])))\n",
        "\n",
        "# 출발어(src)와 도착어(tgt) 문자열들을 텐서 인덱스로 변환하는 변형(transform)\n",
        "text_transform = {}\n",
        "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "    text_transform[ln] = sequential_transforms(token_transform[ln], # 토큰화 함수(Tokenization)\n",
        "                                               vocab_transform[ln], # 수치화 함수(Numericalization)\n",
        "                                               tensor_transform) # BOS/EOS를 추가하고 텐서를 생성\n",
        "\n",
        "\n",
        "# 데이터를 텐서로 조합(collate)하는 함수\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = [], []\n",
        "    for src_sample, tgt_sample in batch:\n",
        "        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n",
        "        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n",
        "\n",
        "    #batch로 묶이는 데이터들의 길이가 다르기 때문에 패딩처리\n",
        "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
        "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
        "    return src_batch, tgt_batch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "834096d4-93cd-4632-b468-f890e6ec3d33",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "#모델의 매개변수를 정의하고 객체를 생성\n",
        "torch.manual_seed(0)\n",
        "\n",
        "SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n",
        "TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n",
        "EMB_SIZE = 512\n",
        "NHEAD = 8\n",
        "FFN_HID_DIM = 512\n",
        "#BATCH_SIZE = 128\n",
        "BATCH_SIZE = 64\n",
        "NUM_ENCODER_LAYERS = 6\n",
        "NUM_DECODER_LAYERS = 6\n",
        "\n",
        "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
        "                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
        "\n",
        "for p in transformer.parameters():\n",
        "    if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)\n",
        "\n",
        "transformer = transformer.to(DEVICE[0])\n",
        "\n",
        "#학습 단계에서 사용할 손실 함수(loss function)를 교차 엔트로피 손실(cross-entropy loss)로 정의하고, 옵티마이저(optimizer)도 정의\n",
        "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "\n",
        "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
        "val_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "36fe6ea6-7d3d-47e5-aee0-837cb8caee21",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "#각 에폭(epoch)마다 호출할 학습 및 검증(evaluation) 단계를 정의\n",
        "def train_epoch(model, optimizer, train_dataloader, global_step, best_valid_loss):\n",
        "    model.train()\n",
        "    losses = 0\n",
        "    \n",
        "    for src, tgt in train_dataloader:\n",
        "        start_time = timer()\n",
        "        src = src.to(DEVICE[0])\n",
        "        tgt = tgt.to(DEVICE[0])\n",
        "\n",
        "        tgt_input = tgt[:-1, :]\n",
        "\n",
        "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "\n",
        "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
        "        \n",
        "        # gradient를 0으로 초기화\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        tgt_out = tgt[1:, :]\n",
        "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "        loss.backward()\n",
        "\n",
        "        # W와 b를 업데이트\n",
        "        optimizer.step()\n",
        "        losses += loss.item()\n",
        "        \n",
        "        end_time = timer()\n",
        "        \n",
        "        global_step+= 1\n",
        "        #5000 step에 한번씩 로그 저장 및 로스 값을 비교하여 모델 저장\n",
        "        if(global_step % 5000 == 0 and not global_step == 0):\n",
        "            train_loss = losses / len(train_dataloader)\n",
        "            val_loss = evaluate(model, val_dataloader)            \n",
        "            #print(f\"Step: {global_step}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, Batch time = {(end_time - start_time):.3f}s\")\n",
        "            SetData.write_file('train_status.txt', f\"Step: {global_step}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, Batch time = {(end_time - start_time):.3f}s\")\n",
        "                        \n",
        "            if best_valid_loss > val_loss:\n",
        "                best_valid_loss = val_loss\n",
        "                print('save model')\n",
        "                save_model('models', '/mt-model-old-v20k_v20k', model, optimizer, best_valid_loss)\n",
        "\n",
        "    return losses / len(train_dataloader), global_step, best_valid_loss\n",
        "\n",
        "\n",
        "def evaluate(model, val_dataloader):\n",
        "    model.eval()\n",
        "    losses = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for src, tgt in val_dataloader:\n",
        "            src = src.to(DEVICE[0])\n",
        "            tgt = tgt.to(DEVICE[0])\n",
        "\n",
        "            tgt_input = tgt[:-1, :]\n",
        "\n",
        "            src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "\n",
        "            logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
        "\n",
        "            tgt_out = tgt[1:, :]\n",
        "            loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "            losses += loss.item()\n",
        "\n",
        "    return losses / len(val_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb47e988-9af0-453d-b3c4-186915e2f89c",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "save model\n",
            "save model\n",
            "save model\n",
            "Epoch: 1, Train loss: 2.928, Val loss: 3.189, Epoch time = 1922.667s\n"
          ]
        }
      ],
      "source": [
        "#학습\n",
        "from timeit import default_timer as timer\n",
        "NUM_EPOCHS = 25\n",
        "\n",
        "best_valid_loss = float(\"Inf\")\n",
        "global_step = 0\n",
        "for epoch in range(1, NUM_EPOCHS+1):\n",
        "    start_time = timer()\n",
        "    train_loss, global_step, best_valid_loss = train_epoch(transformer, optimizer, train_dataloader, global_step, best_valid_loss)\n",
        "    val_loss = evaluate(transformer, val_dataloader)\n",
        "    end_time = timer()\n",
        "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
        "    SetData.write_file('train_status.txt', f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, Epoch time = {(end_time - start_time):.3f}s\")\n",
        "    #if best_valid_loss > val_loss:\n",
        "        #best_valid_loss = val_loss\n",
        "        #print('save model')\n",
        "        #save_model('models', '/mt-model-full-v30k_v30k', transformer, optimizer, best_valid_loss)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "torch109_py38",
      "language": "python",
      "name": "torch109_py38"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
